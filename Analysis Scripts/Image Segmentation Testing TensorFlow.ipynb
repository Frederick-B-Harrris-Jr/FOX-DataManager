{"cells":[{"cell_type":"code","execution_count":null,"id":"Of8vlOrAcljW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108,"status":"ok","timestamp":1731470730820,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"Of8vlOrAcljW","outputId":"53772f15-4d71-45ab-855b-a4656160a3a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-13 04:05:30.673\n"]}],"source":["#Timestamps are collected at various stages to understand processing speed.\n","# prompt: print date and time stamp with milliseconds\n","\n","import datetime\n","\n","def current_datetime_millis():\n","  now = datetime.datetime.now()\n","  millis = int(round(now.timestamp() * 1000))\n","  return now.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n","\n","\n","print(current_datetime_millis())"]},{"cell_type":"code","execution_count":null,"id":"tLbxwAEQEvDe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13605,"status":"ok","timestamp":1731470744529,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"tLbxwAEQEvDe","outputId":"f6d3981b-85ee-459a-9d60-fec8a6ca76a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Collecting Image\n","  Downloading image-1.5.33.tar.gz (15 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from Image) (11.0.0)\n","Collecting django (from Image)\n","  Downloading Django-5.1.3-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Image) (1.16.0)\n","Collecting asgiref<4,>=3.8.1 (from django->Image)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting sqlparse>=0.3.1 (from django->Image)\n","  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.8.1->django->Image) (4.12.2)\n","Downloading Django-5.1.3-py3-none-any.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: Image\n","  Building wheel for Image (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Image: filename=image-1.5.33-py2.py3-none-any.whl size=19482 sha256=d05adab8f79094f0ded7737252074a64df44467c79128f643fc043dbbb5d9bba\n","  Stored in directory: /root/.cache/pip/wheels/70/0c/a4/7cfa53a5c6225c2db2bfec08e782b43d0f25fdae2e995b69be\n","Successfully built Image\n","Installing collected packages: sqlparse, asgiref, django, Image\n","Successfully installed Image-1.5.33 asgiref-3.8.1 django-5.1.3 sqlparse-0.5.1\n","Collecting openpyxl\n","  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n","Collecting et-xmlfile (from openpyxl)\n","  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n","Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n","Installing collected packages: et-xmlfile, openpyxl\n","Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n","Collecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynvml\n","Successfully installed pynvml-11.5.3\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"]}],"source":["!pip install matplotlib\n","!pip install Image\n","!pip install openpyxl\n","!pip install pynvml\n","!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":null,"id":"1f0a044c-081c-485d-b747-4503168c5787","metadata":{"id":"1f0a044c-081c-485d-b747-4503168c5787"},"outputs":[],"source":["\n","import copy\n","import os\n","import random\n","import shutil\n","import zipfile\n","from math import atan2, cos, sin, sqrt, pi, log\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","from numpy import linalg as LA\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models, losses, datasets\n","import keras\n","%matplotlib inline\n","import pynvml\n","# for bulding and running deep learning model\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import ZeroPadding2D, ZeroPadding1D, ZeroPadding3D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.utils import normalize\n","import os\n","import cv2\n","from PIL import Image\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","source":["#Device Setup"],"metadata":{"id":"Io_ZFwW3kM8y"},"id":"Io_ZFwW3kM8y"},{"cell_type":"code","execution_count":null,"id":"8-S_YyXpEOVD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134,"status":"ok","timestamp":1731470756698,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"8-S_YyXpEOVD","outputId":"1a077b77-265a-4476-b3cd-25ce60217c7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow is not using the GPU\n"]}],"source":["tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","# Check if TensorFlow is using the GPU\n","if tf.test.is_gpu_available():\n","    print(\"TensorFlow is using the GPU\")\n","\n","    # Initialize the pynvml library\n","    pynvml.nvmlInit()\n","\n","    # Get the number of GPU devices\n","    num_gpus = pynvml.nvmlDeviceGetCount()\n","\n","    # Iterate over GPU devices\n","    for i in range(num_gpus):\n","        # Get the device identifier\n","        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n","        # Get the full GPU name\n","        gpu_name = pynvml.nvmlDeviceGetName(handle)\n","        print(\"GPU Name:\", gpu_name)\n","\n","    # Shutdown the pynvml library\n","    pynvml.nvmlShutdown()\n","else:\n","    print(\"TensorFlow is not using the GPU\")"]},{"cell_type":"code","execution_count":null,"id":"4VwLiHVlEOSI","metadata":{"id":"4VwLiHVlEOSI"},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')"]},{"cell_type":"code","execution_count":null,"id":"LsybgwmVEOPM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1731470756699,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"LsybgwmVEOPM","outputId":"ecb70164-285a-4108-a35c-0e16e2c133cf"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["gpus"]},{"cell_type":"code","execution_count":null,"id":"_dFlS7Z5EOLz","metadata":{"id":"_dFlS7Z5EOLz"},"outputs":[],"source":["#Prevent out of memory error\n","#for gpu in gpus:\n"," #   tf.config.experimental.set_memory_growth(gpu,True)"]},{"cell_type":"markdown","id":"7f783e9f-ef24-4aba-9812-aa6c9985c76e","metadata":{"id":"7f783e9f-ef24-4aba-9812-aa6c9985c76e"},"source":["# Data Import From CVS/XLS\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0a8a0a47-1fd5-4740-b616-ef475c3384ec","metadata":{"id":"0a8a0a47-1fd5-4740-b616-ef475c3384ec"},"outputs":[],"source":["import pandas"]},{"cell_type":"code","execution_count":null,"id":"j0jLGC1UTW5D","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40015,"status":"ok","timestamp":1731470796702,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"j0jLGC1UTW5D","outputId":"fd96d5f5-d6ef-44d7-e6c5-9f072e301456"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m92.2/96.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n","Mounted at /content/drive\n"]}],"source":["!pip install -q xlrd\n","!pip install openpyxl\n","import pandas\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"id":"6d2e9975-eb9e-455e-aa70-3d620ae93a15","metadata":{"id":"6d2e9975-eb9e-455e-aa70-3d620ae93a15"},"outputs":[],"source":["path = \"/content/drive/My Drive/SegmentationList.xlsx\""]},{"cell_type":"code","execution_count":null,"id":"222a3b9d-e729-4b81-ac8b-047ba21bf640","metadata":{"id":"222a3b9d-e729-4b81-ac8b-047ba21bf640"},"outputs":[],"source":["df = pandas.read_excel(path, 7, header=None, names=['masks','images','split'])"]},{"cell_type":"markdown","source":["#Data Processing"],"metadata":{"id":"TAeKa0VokV3Q"},"id":"TAeKa0VokV3Q"},{"cell_type":"code","execution_count":null,"id":"f2cb3193-b965-4d29-b854-4a4505db22cb","metadata":{"id":"f2cb3193-b965-4d29-b854-4a4505db22cb"},"outputs":[],"source":["trainData = df.loc[df['split'] == 'TRAIN']\n","testData = df.loc[df['split'] == 'TEST']"]},{"cell_type":"code","execution_count":null,"id":"66613cb7-5c77-4ab3-bf64-d7f9126e7fa3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1731470799438,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"66613cb7-5c77-4ab3-bf64-d7f9126e7fa3","outputId":"c13164ed-d1c0-4611-f1bd-03dc65d9a89c"},"outputs":[{"name":"stdout","output_type":"stream","text":["10000\n","9000\n","1000\n"]}],"source":["totallen = len(df)\n","trainlen = len(trainData)\n","testlen = len(testData)\n","print(totallen)\n","print(trainlen)\n","print(testlen)"]},{"cell_type":"code","execution_count":null,"id":"dc2d173b-d94a-4055-8cd2-1eb9aa728f59","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1521,"status":"ok","timestamp":1731470800955,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"dc2d173b-d94a-4055-8cd2-1eb9aa728f59","outputId":"8cef3075-409c-4f92-b869-29ed6b4f2df9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training percentage: 80.0\n","Testing percentage: 20.0\n"]}],"source":["# prompt: while training percentage is greater than 80, split the dataset by .01%\n","\n","while (trainlen / totallen) * 100 > 80:\n","  trainData, splitTrained = train_test_split(trainData, test_size=0.0001)\n","  testData = pandas.concat([testData, splitTrained])\n","  trainlen = len(trainData)\n","  testlen = len(testData)\n","print(\"Training percentage:\", (trainlen / totallen) * 100)\n","print(\"Testing percentage:\", (testlen / totallen) * 100)\n"]},{"cell_type":"code","execution_count":null,"id":"lMv6BzE5EGxP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1731470800955,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"lMv6BzE5EGxP","outputId":"09b4cc0a-ba28-432b-95d1-a85d74650a30"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training percentage: 80.0\n","Testing percentage: 20.0\n"]}],"source":["# prompt: while training percentage is greater than 80, split the dataset by .01%\n","\n","while (testlen / totallen) * 100 > 20:\n","  testData, splitTest = train_test_split(testData, test_size=0.0001)\n","  trainData = pandas.concat([trainData, splitTest])\n","  trainlen = len(trainData)\n","  testlen = len(testData)\n","print(\"Training percentage:\", (trainlen / totallen) * 100)\n","print(\"Testing percentage:\", (testlen / totallen) * 100)"]},{"cell_type":"code","execution_count":null,"id":"7fe565a0-d16f-49e1-9bc5-d58501a441fd","metadata":{"id":"7fe565a0-d16f-49e1-9bc5-d58501a441fd"},"outputs":[],"source":["train_image_paths = trainData['images'].values\n","train_mask_paths = trainData['masks'].values"]},{"cell_type":"code","execution_count":null,"id":"22ddd237-f9c6-411a-8beb-6be8276086ce","metadata":{"id":"22ddd237-f9c6-411a-8beb-6be8276086ce"},"outputs":[],"source":["test_image_paths = testData['images'].values\n","test_mask_paths = testData['masks'].values"]},{"cell_type":"code","execution_count":null,"id":"eafc2f49-878d-4c62-9e11-d7f6f953f140","metadata":{"id":"eafc2f49-878d-4c62-9e11-d7f6f953f140"},"outputs":[],"source":["directory = \"/content/drive/My Drive/\"\n","replaceString = \"/Volumes/Frederick Harris II/Dissertation Data/\";"]},{"cell_type":"code","execution_count":null,"id":"c2627077-d8ed-4ef2-affc-7cb7c91956a1","metadata":{"id":"c2627077-d8ed-4ef2-affc-7cb7c91956a1"},"outputs":[],"source":["for i in range(len(train_image_paths)):\n","    train_image_paths[i] = train_image_paths[i].replace(replaceString, directory)\n","\n","for i in range(len(train_mask_paths)):\n","    train_mask_paths[i] = train_mask_paths[i].replace(replaceString, directory)\n","\n","for i in range(len(test_image_paths)):\n","    test_image_paths[i] = test_image_paths[i].replace(replaceString, directory)\n","\n","for i in range(len(test_mask_paths)):\n","    test_mask_paths[i] = test_mask_paths[i].replace(replaceString, directory)"]},{"cell_type":"code","execution_count":null,"id":"74941c92-bc16-47ba-bcb2-a05530874c65","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1731470801048,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"74941c92-bc16-47ba-bcb2-a05530874c65","outputId":"cb241e5e-3394-4adf-e96f-b4fff61863cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["8000\n","8000\n","['/content/drive/My Drive/UECFOODPIXCOMPLETE/train/images/4907.jpg'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/images/1657.jpg'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/images/6577.jpg'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/images/7574.jpg'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/images/189.jpg']\n","['/content/drive/My Drive/UECFOODPIXCOMPLETE/train/masks/4907.png'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/masks/1657.png'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/masks/6577.png'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/masks/7574.png'\n"," '/content/drive/My Drive/UECFOODPIXCOMPLETE/train/masks/189.png']\n"]}],"source":["\n","print(len(train_image_paths))\n","print(len(train_mask_paths))\n","print(train_image_paths[:5])\n","print(train_mask_paths[:5])"]},{"cell_type":"code","execution_count":null,"id":"7e143f1e-5fc4-4bf8-b6ae-0b09aa0c843f","metadata":{"id":"7e143f1e-5fc4-4bf8-b6ae-0b09aa0c843f"},"outputs":[],"source":["#Remove items without proper exts\n","for i in train_image_paths:\n","    if \".jpg\" not in i and \".png\" not in i:\n","        print(i)\n","        train_image_paths.remove(i)"]},{"cell_type":"code","execution_count":null,"id":"759d68fe-3a38-42aa-abe2-14ee7435cfba","metadata":{"id":"759d68fe-3a38-42aa-abe2-14ee7435cfba"},"outputs":[],"source":["#Remove items without proper exts\n","for i in train_mask_paths:\n","    if \".jpg\" not in i and \".png\" not in i:\n","        print(i)\n","        train_mask_paths.remove(i)"]},{"cell_type":"code","execution_count":null,"id":"91e27b08-60df-4f9a-8e10-bb4e68dc4585","metadata":{"id":"91e27b08-60df-4f9a-8e10-bb4e68dc4585"},"outputs":[],"source":["test_image_paths = sorted(test_image_paths)\n","test_mask_paths = sorted(test_mask_paths)"]},{"cell_type":"code","execution_count":null,"id":"2409f223-f4bc-4f04-82a0-c9f221805440","metadata":{"id":"2409f223-f4bc-4f04-82a0-c9f221805440"},"outputs":[],"source":["#Remove items without proper exts\n","for i in test_image_paths:\n","    if \".jpg\" not in i and \".png\" not in i:\n","        print(i)\n","        test_image_paths.remove(i)"]},{"cell_type":"code","execution_count":null,"id":"13d33379-3774-4f34-85cc-ca412651b783","metadata":{"id":"13d33379-3774-4f34-85cc-ca412651b783"},"outputs":[],"source":["#Remove items without proper exts\n","for i in test_mask_paths:\n","    if \".jpg\" not in i and \".png\" not in i:\n","        print(i)\n","        test_mask_paths.remove(i)"]},{"cell_type":"code","execution_count":null,"id":"11cb360e-3a18-4381-a078-d73824cdda36","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1731470801049,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"11cb360e-3a18-4381-a078-d73824cdda36","outputId":"c0eab72d-0efd-4baf-ceac-d6dac2a6036d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2000\n","2000\n","['/content/drive/My Drive/UECFOODPIXCOMPLETE/test/images/1004.jpg', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/images/1005.jpg', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/images/102.jpg', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/images/103.jpg', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/images/1034.jpg']\n","['/content/drive/My Drive/UECFOODPIXCOMPLETE/test/masks/1004.png', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/masks/1005.png', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/masks/102.png', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/masks/103.png', '/content/drive/My Drive/UECFOODPIXCOMPLETE/test/masks/1034.png']\n"]}],"source":["print(len(test_image_paths))\n","print(len(test_mask_paths))\n","print(test_image_paths[:5])\n","print(test_mask_paths[:5])"]},{"cell_type":"code","execution_count":null,"id":"yPhChB5QXVzC","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1731470801050,"user":{"displayName":"Fred Harris","userId":"12177852022260971346"},"user_tz":360},"id":"yPhChB5QXVzC","outputId":"eeaf91f7-f04c-4d4f-9a42-39d3fa5ed487"},"outputs":[{"name":"stdout","output_type":"stream","text":["current time:- 2024-11-13 04:06:40.979615\n"]}],"source":["import datetime;\n","\n","# ct stores current time\n","ts = datetime.datetime.now()\n","print(\"current time:-\", ts)"]},{"cell_type":"code","execution_count":null,"id":"jq3jVePnMj7x","metadata":{"id":"jq3jVePnMj7x"},"outputs":[],"source":["train_y = []\n","train_x = []\n","\n","SIZE = 128\n","img_shape = (SIZE,SIZE,3)\n","mask_shape = (SIZE,SIZE,1)"]},{"cell_type":"markdown","source":["##Convert data to numpy array for simpler processng"],"metadata":{"id":"z-U_RSfakfQB"},"id":"z-U_RSfakfQB"},{"cell_type":"code","execution_count":null,"id":"9vlp7PjqCzbi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vlp7PjqCzbi","outputId":"a3651619-d707-42a4-c62e-53502c0c36b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-13 04:07:23.152469   0 % ( 0  /  8000 )\n","2024-11-13 04:14:09.198770   10 % ( 800  /  8000 )\n","2024-11-13 04:21:02.444161   20 % ( 1600  /  8000 )\n","2024-11-13 04:27:25.000056   30 % ( 2400  /  8000 )\n","2024-11-13 04:34:03.741016   40 % ( 3200  /  8000 )\n","2024-11-13 04:40:28.284999   50 % ( 4000  /  8000 )\n"]}],"source":["progress = 0\n","progInt = 10\n","for i in range(len(train_image_paths)):    #Remember enumerate method adds a counter and returns the enumerate object\n","      image = cv2.imread(train_image_paths[i], 1) #RGB\n","      image = Image.fromarray(image)\n","      image = image.resize((SIZE, SIZE))\n","      train_x.append(np.array(image))\n","\n","      mask = cv2.imread(train_mask_paths[i], 0)\n","      mask = Image.fromarray(mask)\n","      mask = mask.resize((SIZE, SIZE))\n","      train_y.append(np.array(mask))\n","\n","      if(100*(i/len(train_image_paths)) >= progress):\n","        ts = datetime.datetime.now()\n","        print(ts, \" \" ,progress, \"% (\", i, \" / \", len(train_image_paths), \")\")\n","        progress += progInt\n","\n","print(ts, \" 100 %\")"]},{"cell_type":"code","execution_count":null,"id":"F6giSWBNsOZt","metadata":{"id":"F6giSWBNsOZt"},"outputs":[],"source":["test_y = []\n","test_x = []"]},{"cell_type":"code","execution_count":null,"id":"dgSwGYx5CzUg","metadata":{"id":"dgSwGYx5CzUg"},"outputs":[],"source":["progress = 0\n","progInt = 10\n","for i in range(len(test_image_paths)):    #Remember enumerate method adds a counter and returns the enumerate object\n","      image = cv2.imread(test_image_paths[i], 1) #RGB\n","      image = Image.fromarray(image)\n","      image = image.resize((SIZE, SIZE))\n","      test_x.append(np.array(image))\n","\n","      mask = cv2.imread(test_mask_paths[i], 0)\n","      mask = Image.fromarray(mask)\n","      mask = mask.resize((SIZE, SIZE))\n","      test_y.append(np.array(mask))\n","\n","      if(100*(i/len(test_image_paths)) > progress):\n","        ts = datetime.datetime.now()\n","        print(ts, \" \" ,progress, \"% (\", i, \" / \", len(test_image_paths), \")\")\n","        progress += progInt\n","\n","print(ts, \"  100 %\")"]},{"cell_type":"code","execution_count":null,"id":"BVG8bsiOcrIN","metadata":{"id":"BVG8bsiOcrIN"},"outputs":[],"source":["print(current_datetime_millis())"]},{"cell_type":"markdown","source":["## Data normalization"],"metadata":{"id":"t_XVvS1IkpJR"},"id":"t_XVvS1IkpJR"},{"cell_type":"code","execution_count":null,"id":"1wNkowFnCy-w","metadata":{"id":"1wNkowFnCy-w"},"outputs":[],"source":["#Normalize images\n","train_x = np.expand_dims(normalize(np.array(train_x), axis=1),3)\n","\n","#Do not normalize masks, just rescale to 0 to 1.\n","train_y = np.expand_dims((np.array(train_y)),3) /255."]},{"cell_type":"code","execution_count":null,"id":"SoV2O-CJFjYM","metadata":{"id":"SoV2O-CJFjYM"},"outputs":[],"source":["#Normalize images\n","test_x = np.expand_dims(normalize(np.array(test_x), axis=1),3)\n","#D not normalize masks, just rescale to 0 to 1.\n","test_y = np.expand_dims((np.array(test_y)),3) /255."]},{"cell_type":"code","execution_count":null,"id":"jgtJDN4317rZ","metadata":{"id":"jgtJDN4317rZ"},"outputs":[],"source":["train_x.shape"]},{"cell_type":"code","execution_count":null,"id":"8RL0ee2_17cm","metadata":{"id":"8RL0ee2_17cm"},"outputs":[],"source":["train_x = np.squeeze(train_x, 3)"]},{"cell_type":"code","execution_count":null,"id":"_OIhP6hE2a8y","metadata":{"id":"_OIhP6hE2a8y"},"outputs":[],"source":["train_x.shape"]},{"cell_type":"code","execution_count":null,"id":"naCTZQK-yc-7","metadata":{"id":"naCTZQK-yc-7"},"outputs":[],"source":["train_y.shape"]},{"cell_type":"code","execution_count":null,"id":"pqvsDn2ryhY3","metadata":{"id":"pqvsDn2ryhY3"},"outputs":[],"source":["test_x.shape"]},{"cell_type":"code","execution_count":null,"id":"fSlk3u3v4LZb","metadata":{"id":"fSlk3u3v4LZb"},"outputs":[],"source":["test_x = np.squeeze(test_x, 3)"]},{"cell_type":"code","execution_count":null,"id":"eK3pHcdkxfBU","metadata":{"id":"eK3pHcdkxfBU"},"outputs":[],"source":["test_x.shape"]},{"cell_type":"code","execution_count":null,"id":"rtULRJ-wyjWw","metadata":{"id":"rtULRJ-wyjWw"},"outputs":[],"source":["test_y.shape"]},{"cell_type":"code","execution_count":null,"id":"86Z4U-v_TpkU","metadata":{"id":"86Z4U-v_TpkU"},"outputs":[],"source":["SIZE"]},{"cell_type":"markdown","source":["## Data splitting"],"metadata":{"id":"cjSFW2kwksM_"},"id":"cjSFW2kwksM_"},{"cell_type":"code","execution_count":null,"id":"Xm-kndP4Fp9z","metadata":{"id":"Xm-kndP4Fp9z"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_valid, test_x, Y_valid, test_y = train_test_split(test_x, test_y, test_size = 0.50, random_state = 0)\n","#X_valid, train_x, Y_valid, train_y = train_test_split(train_x, train_y, test_size = 0.20, random_state = 0)\n"]},{"cell_type":"code","execution_count":null,"id":"mRFFJIsXJHWG","metadata":{"id":"mRFFJIsXJHWG"},"outputs":[],"source":["# prompt: perform the same shuffle on train_x and train_y\n","\n","from sklearn.utils import shuffle\n","\n","train_x, train_y = shuffle(train_x, train_y, random_state=0)\n","test_x, test_y = shuffle(test_x, test_y, random_state=0)\n","X_valid, Y_valid = shuffle(X_valid, Y_valid, random_state=0)\n"]},{"cell_type":"code","execution_count":null,"id":"RWEBUA47aYGi","metadata":{"id":"RWEBUA47aYGi"},"outputs":[],"source":["SIZE"]},{"cell_type":"markdown","source":["#ML Algorithm Setup"],"metadata":{"id":"BKOxpgiTkybh"},"id":"BKOxpgiTkybh"},{"cell_type":"code","execution_count":null,"id":"6p7TGSjl4bqb","metadata":{"id":"6p7TGSjl4bqb"},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Layer\n","from tensorflow.keras import backend as K\n","\n","def jacard_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n","\n","\n","def jacard_coef_loss(y_true, y_pred):\n","    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function\n"]},{"cell_type":"code","execution_count":null,"id":"KNP6F04b03gl","metadata":{"id":"KNP6F04b03gl"},"outputs":[],"source":["# DeepLabV3+ Model"]},{"cell_type":"code","execution_count":null,"id":"YsTP0FNIwd9s","metadata":{"id":"YsTP0FNIwd9s"},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, UpSampling2D\n","from tensorflow.keras.layers import AveragePooling2D, Conv2DTranspose, Concatenate, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import ResNet50\n","\n","\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n","def ASPP_DLV3(inputs):\n","    shape = inputs.shape\n","\n","    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n","    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n","    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n","    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n","    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n","\n","    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n","    y_1 = BatchNormalization()(y_1)\n","    y_1 = Activation('relu')(y_1)\n","\n","    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n","    y_6 = BatchNormalization()(y_6)\n","    y_6 = Activation('relu')(y_6)\n","\n","    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n","    y_12 = BatchNormalization()(y_12)\n","    y_12 = Activation('relu')(y_12)\n","\n","    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n","    y_18 = BatchNormalization()(y_18)\n","    y_18 = Activation('relu')(y_18)\n","\n","    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n","\n","    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation('relu')(y)\n","    return y\n","\n","def DeepLabV3Plus(shape):\n","    \"\"\" Inputs \"\"\"\n","    inputs = Input(shape)\n","\n","    \"\"\" Pre-trained ResNet50 \"\"\"\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n","\n","    \"\"\" Pre-trained ResNet50 Output \"\"\"\n","    image_features = base_model.get_layer('conv4_block6_out').output\n","    x_a = ASPP_DLV3(image_features)\n","    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n","\n","    \"\"\" Get low-level features \"\"\"\n","    x_b = base_model.get_layer('conv2_block2_out').output\n","    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n","    x_b = BatchNormalization()(x_b)\n","    x_b = Activation('relu')(x_b)\n","\n","    x = Concatenate()([x_a, x_b])\n","\n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n","\n","    \"\"\" Outputs \"\"\"\n","    x = Conv2D(1, (1, 1), name='output_layer')(x)\n","    x = Activation('sigmoid')(x)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","def DeepLabV3PlusNoWeights(shape):\n","    \"\"\" Inputs \"\"\"\n","    inputs = Input(shape)\n","\n","    \"\"\" Pre-trained ResNet50 \"\"\"\n","    base_model = ResNet50(weights=None, include_top=False, input_tensor=inputs)\n","\n","    \"\"\" Pre-trained ResNet50 Output \"\"\"\n","    image_features = base_model.get_layer('conv4_block6_out').output\n","    x_a = ASPP_DLV3(image_features)\n","    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n","\n","    \"\"\" Get low-level features \"\"\"\n","    x_b = base_model.get_layer('conv2_block2_out').output\n","    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n","    x_b = BatchNormalization()(x_b)\n","    x_b = Activation('relu')(x_b)\n","\n","    x = Concatenate()([x_a, x_b])\n","\n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n","\n","    \"\"\" Outputs \"\"\"\n","    x = Conv2D(1, (1, 1), name='output_layer')(x)\n","    x = Activation('sigmoid')(x)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","if False:\n","    input_shape = (512, 512, 3)\n","    model = DeepLabV3Plus(input_shape)\n","    model.summary()"]},{"cell_type":"code","execution_count":null,"id":"TvMP_s7u1K4d","metadata":{"id":"TvMP_s7u1K4d"},"outputs":[],"source":["#Unet"]},{"cell_type":"code","execution_count":null,"id":"cuLgRrMCFVis","metadata":{"id":"cuLgRrMCFVis"},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n","from tensorflow.keras.models import Model\n","\n","def conv_block_unet(input, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def encoder_block_unet(input, num_filters):\n","    x = conv_block_unet(input, num_filters)\n","    p = MaxPool2D((2, 2))(x)\n","    return x, p\n","\n","def decoder_block_unet(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block_unet(x, num_filters)\n","    return x\n","\n","def build_unet(input_shape):\n","    inputs = Input(input_shape)\n","\n","    s1, p1 = encoder_block_unet(inputs, 64)\n","    s2, p2 = encoder_block_unet(p1, 128)\n","    s3, p3 = encoder_block_unet(p2, 256)\n","    s4, p4 = encoder_block_unet(p3, 512)\n","\n","    b1 = conv_block_unet(p4, 1024)\n","\n","    d1 = decoder_block_unet(b1, s4, 512)\n","    d2 = decoder_block_unet(d1, s3, 256)\n","    d3 = decoder_block_unet(d2, s2, 128)\n","    d4 = decoder_block_unet(d3, s1, 64)\n","\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    model = Model(inputs, outputs, name=\"U-Net\")\n","    return model\n","\n","if False:\n","    input_shape = (512, 512, 3)\n","    model = build_unet(input_shape)\n","    model.summary()"]},{"cell_type":"code","execution_count":null,"id":"r0FpuHez3k_x","metadata":{"id":"r0FpuHez3k_x"},"outputs":[],"source":["# Double UNEt"]},{"cell_type":"code","execution_count":null,"id":"EdPgRhFJGrze","metadata":{"id":"EdPgRhFJGrze"},"outputs":[],"source":["\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG19\n","\n","def squeeze_excite_block(inputs, ratio=8):\n","    init = inputs       ## (b, 128, 128, 32)\n","    channel_axis = -1\n","    filters = init.shape[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    se = GlobalAveragePooling2D()(init)     ## (b, 32)   -> (b, 1, 1, 32)\n","    se = Reshape(se_shape)(se)\n","    se = Dense(filters//ratio, activation=\"relu\", use_bias=False)(se)\n","    se = Dense(filters, activation=\"sigmoid\", use_bias=False)(se)\n","\n","    x = Multiply()([inputs, se])\n","    return x\n","\n","def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Activation(\"relu\")(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Activation(\"relu\")(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Activation(\"relu\")(y3)\n","\n","    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Activation(\"relu\")(y4)\n","\n","    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Activation(\"relu\")(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation(\"relu\")(y)\n","\n","    return y\n","\n","def conv_block(x, filters):\n","    x = Conv2D(filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = squeeze_excite_block(x)\n","\n","    return x\n","\n","def encoder1(inputs):\n","    skip_connections = []\n","\n","    model = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n","    for name in names:\n","        skip_connections.append(model.get_layer(name).output)\n","\n","    output = model.get_layer(\"block5_conv4\").output\n","    return output, skip_connections\n","\n","def encoder1NoWeights(inputs):\n","    skip_connections = []\n","\n","    model = VGG19(include_top=False, weights=None, input_tensor=inputs)\n","    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n","    for name in names:\n","        skip_connections.append(model.get_layer(name).output)\n","\n","    output = model.get_layer(\"block5_conv4\").output\n","    return output, skip_connections\n","\n","def decoder1(inputs, skip_connections):\n","    num_filters = [256, 128, 64, 32]\n","    skip_connections.reverse()\n","\n","    x = inputs\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation=\"bilinear\")(x)\n","        x = Concatenate()([x, skip_connections[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def output_block(inputs):\n","    x = Conv2D(1, 1, padding=\"same\")(inputs)\n","    x = Activation(\"sigmoid\")(x)\n","    return x\n","\n","def encoder2(inputs):\n","    num_filters = [32, 64, 128, 256]\n","    skip_connections = []\n","\n","    x = inputs\n","    for i, f in enumerate(num_filters):\n","        x = conv_block(x, f)\n","        skip_connections.append(x)\n","        x = MaxPool2D((2, 2))(x)\n","\n","    return x, skip_connections\n","\n","def decoder2(inputs, skip_1, skip_2):\n","    num_filters = [256, 128, 64, 32]\n","    skip_2.reverse()\n","\n","    x = inputs\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation=\"bilinear\")(x)\n","        x = Concatenate()([x, skip_1[i], skip_2[i]])\n","        x = conv_block(x, f)\n","\n","    return x\n","\n","def build_double_unet_model(input_shape):\n","    inputs = Input(input_shape)\n","    x, skip_1 = encoder1(inputs)\n","    x = ASPP(x, 64)\n","    x = decoder1(x, skip_1)\n","    output1 = output_block(x)\n","\n","    x = inputs * output1\n","\n","    x, skip_2 = encoder2(x)\n","    x = ASPP(x, 64)\n","    x = decoder2(x, skip_1, skip_2)\n","    output2 = output_block(x)\n","\n","    outputs = Concatenate()([output1, output2])\n","    model = Model(inputs, outputs)\n","    return model\n","\n","def build_double_unet_model_no_weights(input_shape):\n","    inputs = Input(input_shape)\n","    x, skip_1 = encoder1NoWeights(inputs)\n","    x = ASPP(x, 64)\n","    x = decoder1(x, skip_1)\n","    output1 = output_block(x)\n","\n","    x = inputs * output1\n","\n","    x, skip_2 = encoder2(x)\n","    x = ASPP(x, 64)\n","    x = decoder2(x, skip_1, skip_2)\n","    output2 = output_block(x)\n","\n","    outputs = Concatenate()([output1, output2])\n","    model = Model(inputs, outputs)\n","    return model\n","\n","if False:\n","    input_shape = (256, 256, 3)\n","    model = build_double_unet_model(input_shape)\n","    model.summary()"]},{"cell_type":"code","execution_count":null,"id":"aBDfva6N3fVh","metadata":{"id":"aBDfva6N3fVh"},"outputs":[],"source":["#ResNet"]},{"cell_type":"code","execution_count":null,"id":"M1Vi1YE53dQs","metadata":{"id":"M1Vi1YE53dQs"},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Input\n","from tensorflow.keras.models import Model\n","\n","def batchnorm_relu_resnet(inputs):\n","    \"\"\" Batch Normalization & ReLU \"\"\"\n","    x = BatchNormalization()(inputs)\n","    x = Activation(\"relu\")(x)\n","    return x\n","\n","def residual_block_resnet(inputs, num_filters, strides=1):\n","    \"\"\" Convolutional Layers \"\"\"\n","    x = batchnorm_relu_resnet(inputs)\n","    x = Conv2D(num_filters, 3, padding=\"same\", strides=strides)(x)\n","    x = batchnorm_relu_resnet(x)\n","    x = Conv2D(num_filters, 3, padding=\"same\", strides=1)(x)\n","\n","    \"\"\" Shortcut Connection (Identity Mapping) \"\"\"\n","    s = Conv2D(num_filters, 1, padding=\"same\", strides=strides)(inputs)\n","\n","    \"\"\" Addition \"\"\"\n","    x = x + s\n","    return x\n","\n","def decoder_block_resnet(inputs, skip_features, num_filters):\n","    \"\"\" Decoder Block \"\"\"\n","\n","    x = UpSampling2D((2, 2))(inputs)\n","    x = Concatenate()([x, skip_features])\n","    x = residual_block_resnet(x, num_filters, strides=1)\n","    return x\n","\n","def build_resunet(input_shape):\n","    \"\"\" RESUNET Architecture \"\"\"\n","\n","    inputs = Input(input_shape)\n","\n","    \"\"\" Endoder 1 \"\"\"\n","    x = Conv2D(64, 3, padding=\"same\", strides=1)(inputs)\n","    x = batchnorm_relu_resnet(x)\n","    x = Conv2D(64, 3, padding=\"same\", strides=1)(x)\n","    s = Conv2D(64, 1, padding=\"same\")(inputs)\n","    s1 = x + s\n","\n","    \"\"\" Encoder 2, 3 \"\"\"\n","    s2 = residual_block_resnet(s1, 128, strides=2)\n","    s3 = residual_block_resnet(s2, 256, strides=2)\n","\n","    \"\"\" Bridge \"\"\"\n","    b = residual_block_resnet(s3, 512, strides=2)\n","\n","    \"\"\" Decoder 1, 2, 3 \"\"\"\n","    x = decoder_block_resnet(b, s3, 256)\n","    x = decoder_block_resnet(x, s2, 128)\n","    x = decoder_block_resnet(x, s1, 64)\n","\n","    \"\"\" Classifier \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs, outputs, name=\"RESUNET\")\n","\n","    return model\n","\n","if False:\n","    shape = (224, 224, 3)\n","    model = build_resunet(shape)\n","    model.summary()"]},{"cell_type":"markdown","source":["#ML Algortithm testing"],"metadata":{"id":"O9wJE57yk6YJ"},"id":"O9wJE57yk6YJ"},{"cell_type":"code","execution_count":null,"id":"XDhpAKKY4Vwu","metadata":{"id":"XDhpAKKY4Vwu"},"outputs":[],"source":["epoch_num = 30\n","batch_num = 1\n","lr = 0.00001\n"]},{"cell_type":"code","execution_count":null,"id":"K3S60vwAgN8r","metadata":{"id":"K3S60vwAgN8r"},"outputs":[],"source":["num_classes = 2"]},{"cell_type":"code","execution_count":null,"id":"sYyr-BdgVohw","metadata":{"id":"sYyr-BdgVohw"},"outputs":[],"source":["print(current_datetime_millis())"]},{"cell_type":"code","execution_count":null,"id":"1u_utoQYd78y","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1u_utoQYd78y","outputId":"85d782ca-426b-4000-e1d8-bd9a6038133c"},"outputs":[{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 28s 854ms/step - loss: -0.0525 - jacard_coef: 0.0530\n","32/32 [==============================] - 26s 810ms/step\n","IoU: 0.37506425\n"]}],"source":["from tensorflow.keras.metrics import MeanIoU\n","writeDir = \"/content/drive/My Drive\"\n","outfilepath = 'config_output_3.txt'\n","iterations = 40\n","\n","for i in range(iterations):\n","\n","  #create and compile models\n","  unet = build_unet(img_shape)\n","  unet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr), loss = [jacard_coef_loss], metrics = [jacard_coef])\n","\n","  resnet = build_resunet(img_shape)\n","  resnet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr), loss = [jacard_coef_loss], metrics = [jacard_coef])\n","\n","  # Create data output\n","  dataOutput = []\n","\n","\n","\n","  historyUnet = unet.fit(x=train_x, y=train_y,\n","                    batch_size = batch_num,\n","                    verbose=0,\n","                    epochs=epoch_num,\n","                    validation_data=(X_valid, Y_valid),\n","                    shuffle=True)\n","\n","  accuracy = historyUnet.history['jacard_coef']\n","  mean_accuracy = np.mean(accuracy)\n","\n","  val_jacard_coef = historyUnet.history['val_jacard_coef']\n","  mean_val_jacard_coef = np.mean(val_jacard_coef)\n","\n","  loss = historyUnet.history['loss']\n","  mean_loss = np.mean(loss)\n","\n","  dataOutput.append(mean_accuracy)\n","  dataOutput.append(mean_val_jacard_coef)\n","  dataOutput.append(mean_loss)\n","\n","  # evaluate model\n","  loss, acc, *other = unet.evaluate(test_x, test_y)\n","  dataOutput.append(acc)\n","  dataOutput.append(0)\n","  dataOutput.append(loss)\n","\n","  y_pred = unet.predict(test_x)\n","  y_pred_classes = (y_pred > 0.5).astype(int)\n","  iou_metric = MeanIoU(num_classes=num_classes)\n","  iou_metric.update_state(test_y, y_pred_classes)\n","  iou = iou_metric.result().numpy()\n","  print(\"IoU:\", iou)\n","  dataOutput.append(iou)\n","\n","  historyResnet = resnet.fit(x=train_x, y=train_y,\n","                    batch_size = batch_num,\n","                    verbose=0,\n","                    epochs=epoch_num,\n","                    validation_data=(X_valid, Y_valid),\n","                    shuffle=True)\n","\n","  accuracy = historyResnet.history['jacard_coef']\n","  mean_accuracy = np.mean(accuracy)\n","\n","  val_jacard_coef =historyResnet.history['val_jacard_coef']\n","  mean_val_jacard_coef = np.mean(val_jacard_coef)\n","\n","  loss = historyResnet.history['loss']\n","  mean_loss = np.mean(loss)\n","\n","  dataOutput.append(mean_accuracy)\n","  dataOutput.append(mean_val_jacard_coef)\n","  dataOutput.append(mean_loss)\n","\n","  # evaluate model\n","  loss, acc, *other = resnet.evaluate(test_x, test_y)\n","  dataOutput.append(acc)\n","  dataOutput.append(0)\n","  dataOutput.append(loss)\n","\n","  y_pred = resnet.predict(test_x)\n","  y_pred_classes = (y_pred > 0.5).astype(int)\n","  iou_metric = MeanIoU(num_classes=num_classes)\n","  iou_metric.update_state(test_y, y_pred_classes)\n","  iou = iou_metric.result().numpy()\n","  dataOutput.append(iou)\n","\n","  #Save data ouptut\n","  filename = os.path.join(writeDir, outfilepath)\n","\n","  if not os.path.exists(filename):\n","    with open(filename, 'w') as f:\n","      pass  # Create an empty file if it doesn't exist\n","\n","  with open(filename, 'a') as f:\n","    f.write(' '.join(map(str, dataOutput)) + '\\n')\n","    print(\"Data saved to\", filename)\n","    print(current_datetime_millis())\n"]},{"cell_type":"code","execution_count":null,"id":"77aa82w7d754","metadata":{"id":"77aa82w7d754"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}